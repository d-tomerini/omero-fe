# -*- coding: utf-8 -*-
"""
Module to call the external backend fastapi app.
It is used to retrieve most of the information that was stored locally before.
I started working with local files rather than databases.
This is good to start, but easier than real life :)
Now I implemented the same pandas dataframe as sql files hosted
by a separate back-end session, that provides this data
This separation of concerns is also good practice
TODO: I'm working with a local sqlite3 database with no json
fields, that's not ideal.
We might switch to postgres/mongodb/dynamoDB
"""

import os

import pandas as pd
import requests
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


def get_dynamic_url():
    """
    Connects to the static address to retrieve the dynamic one.
    Unfortunately the domino app does not expose headless content
    and does not allow for routes. A solution is to use the exposed
    address to redirect the calls to the right place.
    """
    if os.environ.get('DOMINO_PROJECT_OWNER'):
        USER = os.environ.get('DOMINO_PROJECT_OWNER')
        BACKEND_STATIC_URL = f'https://domino-qa-us.cda.cslbehring.com/{USER}/datalake-backend-omeroplus/app'
    else:
        HOSTNAME = os.environ.get('HOSTNAME')
        FASTAPI_PORT = os.environ.get('FASTAPI_PORT')
        BACKEND_STATIC_URL = f'http://{HOSTNAME}:{FASTAPI_PORT}/api/v1'
        return BACKEND_STATIC_URL
    response = requests.get(
        BACKEND_STATIC_URL,
        headers={'Content-type': 'application/json'},
        verify=False
    )
    return response.url.strip('/')

# eventually, probably just better to make a check on the variable once in a while...
# now for testing I load it all the time to avoid wasting time
# DYNAMIC_URL = get_dynamic_url()


db_stores = requests.get(
    get_dynamic_url() + ('/stores/'),
    verify=False
).json()


def get_schema(store):
    """Retrieves the database schema from tables."""
    response = requests.get(
        get_dynamic_url() + (f'/stores/schema/{store}'),
        verify=False
    )
    if response.status_code != 200:
        raise Exception(response.json())
    return response.json()['database_schema']


def search_store_data(store, query_filter=''):
    url = get_dynamic_url() + (f'/search/{store}')
    response = requests.get(
        url,
        params={'q': query_filter},
        verify=False
    )
    if response.status_code != 200:
        raise Exception(response.url, response.text)
    items = response.json()['items']
    return pd.DataFrame.from_records(items)


def search_store_column(store, column=None, query_filter=''):
    """
    Looks for unique values in a column, it returns a few
    """
    url = get_dynamic_url() + f'/search/{store}/distinct/"{column}"'
    response = requests.get(
        url,
        params={'q': query_filter},
        verify=False
    )
    if response.status_code != 200:
        raise Exception(response.url, response.text)
    return response.json()['items']


def get_metadata_fields(store):
    """
    Retrieves a list of fields to create a metadata file associated.
    to a file to be uploaded. Several properties are taken and used.
    """
    url = get_dynamic_url() + f'/upload/{store}/fields'
    response = requests.get(
        url,
        verify=False
    )
    if response.status_code != 200:
        raise Exception(response.url, response.text)
    return response.json()['fields']


def upload_files_data_metadata(files, store):
    """
    Takes care of the upload to s3, where further operation
    will be invoked to fill the autogenerated keys.
    """
    url = get_dynamic_url() + f'/upload/{store}/to_landing_zone'
    response = requests.post(
        url,
        files=files,
        verify=False
    )
    if response.status_code != 200:
        raise Exception(response.url, response.text)
    return response.json()
